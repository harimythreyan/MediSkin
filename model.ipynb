{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6b4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import joblib\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e9cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10015, 2353)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>163</td>\n",
       "      <td>201</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>143</td>\n",
       "      <td>103</td>\n",
       "      <td>119</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>194</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        192        153        193        195        155        192   \n",
       "1         25         14         30         68         48         75   \n",
       "2        192        138        153        200        145        163   \n",
       "3         38         19         30         95         59         72   \n",
       "4        158        113        139        194        144        174   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "0        197        154        185        202  ...        173        124   \n",
       "1        123         93        126        158  ...         60         39   \n",
       "2        201        142        160        206  ...        167        129   \n",
       "3        143        103        119        171  ...         44         26   \n",
       "4        215        162        191        225  ...        209        166   \n",
       "\n",
       "   pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "0        138        183        147        166        185        154   \n",
       "1         55         25         14         28         25         14   \n",
       "2        143        159        124        142        136        104   \n",
       "3         36         25         12         17         25         12   \n",
       "4        185        172        135        149        109         78   \n",
       "\n",
       "   pixel2351  label  \n",
       "0        177      2  \n",
       "1         27      2  \n",
       "2        117      2  \n",
       "3         15      2  \n",
       "4         92      2  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and inspect data\n",
    "data = pd.read_csv('input/hmnist_28_28_RGB.csv')\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c819e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (10015, 2352)\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels\n",
    "y = data['label']\n",
    "X = data.drop(columns=['label'])\n",
    "print(\"Features shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4182290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv('input/HAM10000_metadata.csv')\n",
    "metadata.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80767d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class dictionary\n",
    "classes = {\n",
    "    0: ('akiec', 'Actinic keratoses and intraepithelial carcinomae'),  \n",
    "    1: ('bcc', 'Basal cell carcinoma'), \n",
    "    2: ('bkl', 'Benign keratosis-like lesions'), \n",
    "    3: ('df', 'Dermatofibroma'),\n",
    "    4: ('nv', 'Melanocytic nevi'),  \n",
    "    5: ('vasc', 'Pyogenic granulomas and hemorrhage'), \n",
    "    6: ('mel', 'Melanoma')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b4df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='dx', data=metadata)\n",
    "plt.xlabel('Disease', size=16)\n",
    "plt.ylabel('Frequency', size=16)\n",
    "plt.title('Frequency Distribution of Classes', size=18)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('disease_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2623db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gender distribution\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(metadata['sex'].value_counts(), \n",
    "        labels=metadata['sex'].value_counts().index, \n",
    "        autopct=\"%.1f%%\")\n",
    "plt.title('Gender of Patient', size=18)\n",
    "plt.savefig('gender_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba547edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize age distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(metadata['age'], bins=20)\n",
    "plt.title('Age Distribution of Patients', size=18)\n",
    "plt.xlabel('Age', size=14)\n",
    "plt.ylabel('Count', size=14)\n",
    "plt.savefig('age_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "debe5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: label\n",
      "4    6705\n",
      "6    1113\n",
      "2    1099\n",
      "1     514\n",
      "0     327\n",
      "5     142\n",
      "3     115\n",
      "Name: count, dtype: int64\n",
      "Class distribution after oversampling: label\n",
      "2    6705\n",
      "4    6705\n",
      "3    6705\n",
      "6    6705\n",
      "5    6705\n",
      "1    6705\n",
      "0    6705\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance dataset using oversampling\n",
    "print(\"Class distribution before oversampling:\", y.value_counts())\n",
    "oversample = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "print(\"Class distribution after oversampling:\", pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c62799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped data shape: (46935, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reshape data for CNN input (28×28×3)\n",
    "X_resampled = np.array(X_resampled).reshape(-1, 28, 28, 3)\n",
    "print('Reshaped data shape:', X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2868f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_resampled[i])\n",
    "    plt.title(f\"Class: {y_resampled[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c384342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "X_normalized = (X_resampled - np.mean(X_resampled)) / np.std(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68da2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y_resampled, \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_resampled  # Ensures balanced classes in both train and test sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deaec983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (37548, 28, 28, 3), (37548,)\n",
      "Testing set: (9387, 28, 28, 3), (9387,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb3c777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation for training set to improve generalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e8c1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build improved CNN model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First convolution block\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Second convolution block\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Third convolution block\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8742d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 26, 26, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 11, 11, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 5, 5, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 3, 3, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 357,159\n",
      "Trainable params: 355,495\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "# Callbacks for training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=f\"logs/skin_cancer_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c8b3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with optimized hyperparameters\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f224fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 1.5409 - accuracy: 0.4447\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59007, saving model to best_model.keras\n",
      "586/586 [==============================] - 53s 88ms/step - loss: 1.5409 - accuracy: 0.4447 - val_loss: 1.0627 - val_accuracy: 0.5901 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 1.0858 - accuracy: 0.5905\n",
      "Epoch 2: val_accuracy improved from 0.59007 to 0.70619, saving model to best_model.keras\n",
      "586/586 [==============================] - 51s 86ms/step - loss: 1.0858 - accuracy: 0.5905 - val_loss: 0.8054 - val_accuracy: 0.7062 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.9312 - accuracy: 0.6560\n",
      "Epoch 3: val_accuracy did not improve from 0.70619\n",
      "586/586 [==============================] - 50s 86ms/step - loss: 0.9312 - accuracy: 0.6560 - val_loss: 0.7776 - val_accuracy: 0.6955 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.8286 - accuracy: 0.6951\n",
      "Epoch 4: val_accuracy improved from 0.70619 to 0.73442, saving model to best_model.keras\n",
      "586/586 [==============================] - 50s 86ms/step - loss: 0.8286 - accuracy: 0.6951 - val_loss: 0.6884 - val_accuracy: 0.7344 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.7581 - accuracy: 0.7200\n",
      "Epoch 5: val_accuracy improved from 0.73442 to 0.75711, saving model to best_model.keras\n",
      "586/586 [==============================] - 52s 89ms/step - loss: 0.7581 - accuracy: 0.7200 - val_loss: 0.6325 - val_accuracy: 0.7571 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.7401\n",
      "Epoch 6: val_accuracy improved from 0.75711 to 0.77810, saving model to best_model.keras\n",
      "586/586 [==============================] - 60s 102ms/step - loss: 0.7005 - accuracy: 0.7401 - val_loss: 0.5714 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.7613\n",
      "Epoch 7: val_accuracy improved from 0.77810 to 0.81016, saving model to best_model.keras\n",
      "586/586 [==============================] - 58s 99ms/step - loss: 0.6497 - accuracy: 0.7613 - val_loss: 0.5063 - val_accuracy: 0.8102 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.7744\n",
      "Epoch 8: val_accuracy did not improve from 0.81016\n",
      "586/586 [==============================] - 55s 94ms/step - loss: 0.6155 - accuracy: 0.7744 - val_loss: 0.4901 - val_accuracy: 0.8089 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.7862\n",
      "Epoch 9: val_accuracy improved from 0.81016 to 0.83445, saving model to best_model.keras\n",
      "586/586 [==============================] - 50s 85ms/step - loss: 0.5787 - accuracy: 0.7862 - val_loss: 0.4499 - val_accuracy: 0.8345 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.7979\n",
      "Epoch 10: val_accuracy did not improve from 0.83445\n",
      "586/586 [==============================] - 51s 86ms/step - loss: 0.5482 - accuracy: 0.7979 - val_loss: 0.4796 - val_accuracy: 0.8156 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.8103\n",
      "Epoch 11: val_accuracy improved from 0.83445 to 0.84628, saving model to best_model.keras\n",
      "586/586 [==============================] - 50s 86ms/step - loss: 0.5180 - accuracy: 0.8103 - val_loss: 0.4001 - val_accuracy: 0.8463 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.8204\n",
      "Epoch 12: val_accuracy improved from 0.84628 to 0.85192, saving model to best_model.keras\n",
      "586/586 [==============================] - 51s 86ms/step - loss: 0.4894 - accuracy: 0.8204 - val_loss: 0.3931 - val_accuracy: 0.8519 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4777 - accuracy: 0.8265\n",
      "Epoch 13: val_accuracy improved from 0.85192 to 0.85544, saving model to best_model.keras\n",
      "586/586 [==============================] - 51s 86ms/step - loss: 0.4777 - accuracy: 0.8265 - val_loss: 0.3713 - val_accuracy: 0.8554 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4592 - accuracy: 0.8336\n",
      "Epoch 14: val_accuracy improved from 0.85544 to 0.87067, saving model to best_model.keras\n",
      "586/586 [==============================] - 50s 86ms/step - loss: 0.4592 - accuracy: 0.8336 - val_loss: 0.3415 - val_accuracy: 0.8707 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8373\n",
      "Epoch 15: val_accuracy did not improve from 0.87067\n",
      "586/586 [==============================] - 50s 86ms/step - loss: 0.4459 - accuracy: 0.8373 - val_loss: 0.3511 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.8435\n",
      "Epoch 16: val_accuracy improved from 0.87067 to 0.88196, saving model to best_model.keras\n",
      "586/586 [==============================] - 65s 111ms/step - loss: 0.4205 - accuracy: 0.8435 - val_loss: 0.3211 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.8454\n",
      "Epoch 17: val_accuracy did not improve from 0.88196\n",
      "586/586 [==============================] - 75s 127ms/step - loss: 0.4167 - accuracy: 0.8454 - val_loss: 0.3367 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8527\n",
      "Epoch 18: val_accuracy improved from 0.88196 to 0.88559, saving model to best_model.keras\n",
      "586/586 [==============================] - 77s 132ms/step - loss: 0.3990 - accuracy: 0.8527 - val_loss: 0.2988 - val_accuracy: 0.8856 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8588\n",
      "Epoch 19: val_accuracy did not improve from 0.88559\n",
      "586/586 [==============================] - 97s 166ms/step - loss: 0.3843 - accuracy: 0.8588 - val_loss: 0.3005 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8631\n",
      "Epoch 20: val_accuracy improved from 0.88559 to 0.89986, saving model to best_model.keras\n",
      "586/586 [==============================] - 131s 224ms/step - loss: 0.3736 - accuracy: 0.8631 - val_loss: 0.2719 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.8663\n",
      "Epoch 21: val_accuracy did not improve from 0.89986\n",
      "586/586 [==============================] - 133s 227ms/step - loss: 0.3640 - accuracy: 0.8663 - val_loss: 0.2972 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8722\n",
      "Epoch 22: val_accuracy did not improve from 0.89986\n",
      "586/586 [==============================] - 90s 153ms/step - loss: 0.3536 - accuracy: 0.8722 - val_loss: 0.2789 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8741\n",
      "Epoch 23: val_accuracy improved from 0.89986 to 0.90615, saving model to best_model.keras\n",
      "586/586 [==============================] - 57s 97ms/step - loss: 0.3496 - accuracy: 0.8741 - val_loss: 0.2459 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8777\n",
      "Epoch 24: val_accuracy improved from 0.90615 to 0.90668, saving model to best_model.keras\n",
      "586/586 [==============================] - 73s 124ms/step - loss: 0.3352 - accuracy: 0.8777 - val_loss: 0.2329 - val_accuracy: 0.9067 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.8777\n",
      "Epoch 25: val_accuracy did not improve from 0.90668\n",
      "586/586 [==============================] - 80s 136ms/step - loss: 0.3353 - accuracy: 0.8777 - val_loss: 0.2574 - val_accuracy: 0.9035 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.8784\n",
      "Epoch 26: val_accuracy did not improve from 0.90668\n",
      "586/586 [==============================] - 79s 135ms/step - loss: 0.3271 - accuracy: 0.8784 - val_loss: 0.2635 - val_accuracy: 0.9040 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.8846\n",
      "Epoch 27: val_accuracy did not improve from 0.90668\n",
      "586/586 [==============================] - 76s 129ms/step - loss: 0.3185 - accuracy: 0.8846 - val_loss: 0.2318 - val_accuracy: 0.9067 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8868\n",
      "Epoch 28: val_accuracy did not improve from 0.90668\n",
      "586/586 [==============================] - 83s 142ms/step - loss: 0.3090 - accuracy: 0.8868 - val_loss: 0.2468 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.8864\n",
      "Epoch 29: val_accuracy improved from 0.90668 to 0.92063, saving model to best_model.keras\n",
      "586/586 [==============================] - 83s 141ms/step - loss: 0.3096 - accuracy: 0.8864 - val_loss: 0.2067 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.8924\n",
      "Epoch 30: val_accuracy did not improve from 0.92063\n",
      "586/586 [==============================] - 84s 144ms/step - loss: 0.2989 - accuracy: 0.8924 - val_loss: 0.2189 - val_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.8935\n",
      "Epoch 31: val_accuracy improved from 0.92063 to 0.93097, saving model to best_model.keras\n",
      "586/586 [==============================] - 90s 154ms/step - loss: 0.2943 - accuracy: 0.8935 - val_loss: 0.1918 - val_accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.8951\n",
      "Epoch 32: val_accuracy did not improve from 0.93097\n",
      "586/586 [==============================] - 96s 164ms/step - loss: 0.2877 - accuracy: 0.8951 - val_loss: 0.1907 - val_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.8973\n",
      "Epoch 33: val_accuracy did not improve from 0.93097\n",
      "586/586 [==============================] - 83s 142ms/step - loss: 0.2814 - accuracy: 0.8973 - val_loss: 0.2800 - val_accuracy: 0.8938 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.8980\n",
      "Epoch 34: val_accuracy did not improve from 0.93097\n",
      "586/586 [==============================] - 84s 144ms/step - loss: 0.2813 - accuracy: 0.8980 - val_loss: 0.2022 - val_accuracy: 0.9236 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.8993\n",
      "Epoch 35: val_accuracy did not improve from 0.93097\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "586/586 [==============================] - 82s 140ms/step - loss: 0.2783 - accuracy: 0.8993 - val_loss: 0.2044 - val_accuracy: 0.9229 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9165\n",
      "Epoch 36: val_accuracy improved from 0.93097 to 0.93715, saving model to best_model.keras\n",
      "586/586 [==============================] - 82s 140ms/step - loss: 0.2285 - accuracy: 0.9165 - val_loss: 0.1624 - val_accuracy: 0.9371 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9214\n",
      "Epoch 37: val_accuracy improved from 0.93715 to 0.94492, saving model to best_model.keras\n",
      "586/586 [==============================] - 79s 134ms/step - loss: 0.2141 - accuracy: 0.9214 - val_loss: 0.1480 - val_accuracy: 0.9449 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2081 - accuracy: 0.9239\n",
      "Epoch 38: val_accuracy did not improve from 0.94492\n",
      "586/586 [==============================] - 58s 99ms/step - loss: 0.2081 - accuracy: 0.9239 - val_loss: 0.1569 - val_accuracy: 0.9391 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9254\n",
      "Epoch 39: val_accuracy improved from 0.94492 to 0.94620, saving model to best_model.keras\n",
      "586/586 [==============================] - 58s 99ms/step - loss: 0.2049 - accuracy: 0.9254 - val_loss: 0.1505 - val_accuracy: 0.9462 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9273\n",
      "Epoch 40: val_accuracy improved from 0.94620 to 0.94652, saving model to best_model.keras\n",
      "586/586 [==============================] - 58s 99ms/step - loss: 0.1995 - accuracy: 0.9273 - val_loss: 0.1468 - val_accuracy: 0.9465 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.9283\n",
      "Epoch 41: val_accuracy improved from 0.94652 to 0.94972, saving model to best_model.keras\n",
      "586/586 [==============================] - 58s 99ms/step - loss: 0.1965 - accuracy: 0.9283 - val_loss: 0.1344 - val_accuracy: 0.9497 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9297\n",
      "Epoch 42: val_accuracy did not improve from 0.94972\n",
      "586/586 [==============================] - 58s 99ms/step - loss: 0.1966 - accuracy: 0.9297 - val_loss: 0.1435 - val_accuracy: 0.9466 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9308\n",
      "Epoch 43: val_accuracy did not improve from 0.94972\n",
      "586/586 [==============================] - 56s 96ms/step - loss: 0.1919 - accuracy: 0.9308 - val_loss: 0.1379 - val_accuracy: 0.9490 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9317\n",
      "Epoch 44: val_accuracy did not improve from 0.94972\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "586/586 [==============================] - 59s 100ms/step - loss: 0.1873 - accuracy: 0.9317 - val_loss: 0.1375 - val_accuracy: 0.9497 - lr: 2.0000e-04\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9339\n",
      "Epoch 45: val_accuracy did not improve from 0.94972\n",
      "586/586 [==============================] - 57s 98ms/step - loss: 0.1823 - accuracy: 0.9339 - val_loss: 0.1363 - val_accuracy: 0.9482 - lr: 4.0000e-05\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9353\n",
      "Epoch 46: val_accuracy did not improve from 0.94972\n",
      "586/586 [==============================] - 60s 102ms/step - loss: 0.1797 - accuracy: 0.9353 - val_loss: 0.1351 - val_accuracy: 0.9489 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9354\n",
      "Epoch 47: val_accuracy did not improve from 0.94972\n",
      "586/586 [==============================] - 60s 102ms/step - loss: 0.1759 - accuracy: 0.9354 - val_loss: 0.1331 - val_accuracy: 0.9479 - lr: 4.0000e-05\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9364\n",
      "Epoch 48: val_accuracy improved from 0.94972 to 0.95036, saving model to best_model.keras\n",
      "586/586 [==============================] - 60s 103ms/step - loss: 0.1764 - accuracy: 0.9364 - val_loss: 0.1315 - val_accuracy: 0.9504 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9376\n",
      "Epoch 49: val_accuracy improved from 0.95036 to 0.95164, saving model to best_model.keras\n",
      "586/586 [==============================] - 60s 102ms/step - loss: 0.1743 - accuracy: 0.9376 - val_loss: 0.1314 - val_accuracy: 0.9516 - lr: 4.0000e-05\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9377\n",
      "Epoch 50: val_accuracy improved from 0.95164 to 0.95185, saving model to best_model.keras\n",
      "586/586 [==============================] - 57s 98ms/step - loss: 0.1731 - accuracy: 0.9377 - val_loss: 0.1296 - val_accuracy: 0.9518 - lr: 4.0000e-05\n",
      "Training completed in 3431.78 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model with data augmentation\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Load the best model for evaluation\n",
    "model = load_model('best_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5519e032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 4s 14ms/step - loss: 0.1296 - accuracy: 0.9518\n",
      "Test accuracy: 0.9518\n",
      "Test loss: 0.1296\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d6a7165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 5s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8106393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.97      1.00      0.99      1341\n",
      "         bcc       0.98      1.00      0.99      1341\n",
      "         bkl       0.91      0.95      0.93      1341\n",
      "          df       1.00      1.00      1.00      1341\n",
      "          nv       0.98      0.74      0.84      1341\n",
      "        vasc       1.00      1.00      1.00      1341\n",
      "         mel       0.84      0.97      0.90      1341\n",
      "\n",
      "    accuracy                           0.95      9387\n",
      "   macro avg       0.96      0.95      0.95      9387\n",
      "weighted avg       0.96      0.95      0.95      9387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[classes[i][0] for i in range(7)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38b03c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\", \n",
    "    xticklabels=[classes[i][0] for i in range(7)],\n",
    "    yticklabels=[classes[i][0] for i in range(7)]\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\", size=14)\n",
    "plt.ylabel(\"True Label\", size=14)\n",
    "plt.title(\"Confusion Matrix\", size=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a728196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy', size=14)\n",
    "plt.xlabel('Epoch', size=12)\n",
    "plt.ylabel('Accuracy', size=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss', size=14)\n",
    "plt.xlabel('Epoch', size=12)\n",
    "plt.ylabel('Loss', size=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a721d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model for deployment\n",
    "\n",
    "# 1. Create export directory\n",
    "export_dir = \"exported_model\"\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edd6c7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture saved as model.json\n",
      "Model weights saved as weights.h5\n",
      "Class labels saved as labels.json\n",
      "Full model saved as full_model.h5\n"
     ]
    }
   ],
   "source": [
    "# 2. Save the model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(export_dir, \"model.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"Model architecture saved as model.json\")\n",
    "\n",
    "# 3. Save the model weights\n",
    "model.save_weights(os.path.join(export_dir, \"weights.h5\"))\n",
    "print(\"Model weights saved as weights.h5\")\n",
    "\n",
    "# 4. Save class labels\n",
    "label_json = {}\n",
    "for class_id, (class_code, class_name) in classes.items():\n",
    "    label_json[str(class_id)] = {\n",
    "        \"code\": class_code,\n",
    "        \"name\": class_name\n",
    "    }\n",
    "\n",
    "with open(os.path.join(export_dir, \"labels.json\"), \"w\") as label_file:\n",
    "    json.dump(label_json, label_file, indent=4)\n",
    "print(\"Class labels saved as labels.json\")\n",
    "\n",
    "# 5. Save the full model in Keras format\n",
    "model.save(os.path.join(export_dir, \"full_model.h5\"))\n",
    "print(\"Full model saved as full_model.h5\")\n",
    "\n",
    "# 6. Function to load the exported model\n",
    "def load_exported_model(export_dir=\"exported_model\"):\n",
    "    # Load model architecture from JSON\n",
    "    with open(os.path.join(export_dir, \"model.json\"), \"r\") as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "    \n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    # Load weights\n",
    "    loaded_model.load_weights(os.path.join(export_dir, \"weights.h5\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    loaded_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"Model loaded successfully from exported files!\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "174f0166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Convert model to TFLite format\n",
    "def convert_to_tflite(export_dir=\"exported_model\"):\n",
    "    # Load the model\n",
    "    model = load_model(os.path.join(export_dir, \"full_model.h5\"))\n",
    "    \n",
    "    # Convert to TFLite format\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    # Enable optimizations\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "    # Convert the model\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Save the TFLite model\n",
    "    with open(os.path.join(export_dir, \"model.tflite\"), \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(\"Model successfully converted to TFLite format\")\n",
    "    return os.path.join(export_dir, \"model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18eb2f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gokul\\AppData\\Local\\Temp\\tmp923dzflp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gokul\\AppData\\Local\\Temp\\tmp923dzflp\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully converted to TFLite format\n"
     ]
    }
   ],
   "source": [
    "# Convert to TFLite\n",
    "tflite_model_path = convert_to_tflite(export_dir)\n",
    "\n",
    "# Function to make predictions on new images\n",
    "def predict_image(image_path, model_path=\"exported_model/full_model.h5\"):\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((28, 28))\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Normalize the image\n",
    "    img_normalized = (img_array - np.mean(img_array)) / np.std(img_array)\n",
    "    \n",
    "    # Reshape for prediction\n",
    "    img_reshaped = img_normalized.reshape(1, 28, 28, 3)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_reshaped)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    \n",
    "    # Get class name and code\n",
    "    class_code, class_name = classes[predicted_class]\n",
    "    \n",
    "    # Calculate confidence\n",
    "    confidence = np.max(predictions) * 100\n",
    "    \n",
    "    print(f\"Predicted class: {predicted_class} - {class_code} ({class_name})\")\n",
    "    print(f\"Confidence: {confidence:.2f}%\")\n",
    "    \n",
    "    # Display the image with prediction\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {class_code}\\n{class_name}\\nConfidence: {confidence:.2f}%\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_class, class_code, class_name, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e167966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
